{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Recommendations Engine (Part 3/3)\n",
    "\n",
    "> This notebook is part of a series of notebooks that will walk you through the process of building a good collaborative recommendations engine (while also including our mistakes that we did). The series is broken up into three parts. If you haven't already, we would recommend you to read the first two parts of the series before continuing on with this one (as we won't repeat the same explanations).\n",
    "\n",
    "- Part 1: Our Attempt at Building an Item-Item Collaborative Recommendations Engine\n",
    "- Part 2: Fixing our Item-Item Collaborative Recommendations Engine\n",
    "- **Part 3: Improving our Collaborative Recommendations Engine by leveraging other techniques than Item-Item Collaborative Filtering...**\n",
    "\n",
    "## Part 3: Improving our Collaborative Recommendations Engine by leveraging other techniques...\n",
    "In Part 2, we were able to have a working-model, but with non-optimal performance. In this notebook, we want to have a look at other techniques that is used in the industry in order to have a better model.\n",
    "\n",
    "Althought our previous code was using Spark + Parallelizations, our algorithm wasn't optimized for large datasets due to cross-joins and many dataframes manipulations. We realized (in Part 2) that our method isn't frequently used in the industry... **We did a mistake.** It is mostly used for small datasets or for educational purposes. We need to think bigger and use a more scalable/efficient solution such as:\n",
    "\n",
    "- _ANN (Approximate Nearest Neighbors)_ which is a technique that is used to find similar items in a large dataset.\n",
    "- _KNN (K-Nearest Neighbors)_ which is also a technique that is used to find similar items in a large dataset.\n",
    "- _SVD (Singular Value Decomposition)_ which is a matrix factorization technique that is used to find latent factors in a large dataset. \n",
    "- _ALS (Alternating Least Squares)_ which is also a matrix factorization technique that is used to find latent factors in a large dataset.\n",
    "\n",
    "In our case, we believe it makes more sense to use ALS since it is a matrix factorization technique that we learned in class where it is using latent factors. We will test it with item-item and user-item using parameters tuning + biases. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col,udf, max, exp\n",
    "from pyspark.sql.types import FloatType, LongType\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Spark Configuration/Setup\n",
    "Idem to Part 2, we will be using Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 00:17:03 WARN Utils: Your hostname, gkill.local resolves to a loopback address: 127.0.0.1; using 192.168.2.13 instead (on interface en0)\n",
      "23/03/26 00:17:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 00:17:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Item-Item Recommender System\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Preparation/Loading\n",
    "Idem to Part 2, we will be using the same dataset + Same Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"data/ratings_small.csv\"\n",
    "data = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "data = data.drop(\"timestamp\")\n",
    "\n",
    "# split data into train and test\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Modeling\n",
    "\n",
    "Define the ALS algorithm for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/26 00:17:17 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/03/26 00:17:17 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/03/26 00:17:17 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create ALS model\n",
    "als = ALS(maxIter=15, rank=10, regParam=0.15, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# fit model\n",
    "model = als.fit(train_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data Prediction\n",
    "The model was then used to make predictions on our test data set. In this step the model adds a column named prediction which is calculated using the learned latent factors and we can use this column to evaluate the performance of the model on the test data set. An example of 5 rows is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   148|    185|   3.0|  3.131124|\n",
      "|   148|    364|   4.0|  4.014933|\n",
      "|   148|    596|   4.5| 3.8559518|\n",
      "|   148|   1028|   5.0| 3.9720638|\n",
      "|   148|   1136|   4.5| 4.3673754|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# show 5 rows\n",
    "predictions.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Model Evaluation\n",
    "\n",
    "Here we chose to use RMSE and R-squared as evaluations which work well for regression based models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.9029\n",
      "R-squared on test data = 0.2613\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using RMSE (Root Mean Squared Error)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = {:.4f}\".format(rmse))\n",
    "\n",
    "# Evaluate the model by calculating the R-squared\n",
    "evaluator_r2 = RegressionEvaluator(metricName=\"r2\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(\"R-squared on test data = {:.4f}\".format(r2))\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Model Performance\n",
    "\n",
    " We tested several different hyperparameters for our model by first running a grid search over the `maxIterations`, `rank` and `regParam`. Initially this led us to believe that a rank of 50 with more latent factors would perform better but upon further evaluation and manually adjusting the parameters individually we discovered our optimal combination of 15, 10 and 0.15 respectively that performed best for our RMSE and R^2 evaluators. While our RMSE performed quite well our R^2 evaluator indicates that our model does not perform well with high variance. This is probably due to the sparse data set. Analysis of the data indicated a sparsity of 98.36% which is quite high and would make it difficult to estimate the user's ratings accurately. \n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Test 1</th>\n",
    "<th>Test 2</th>\n",
    "<th style=\"background: #2fa329\">Test 3</th>\n",
    "<th>Test 4</th>\n",
    "</tr>\n",
    "<tr>\n",
    "\n",
    "<td>\n",
    "\n",
    "| Params Value | RMSE Value | R^2 |Time |\n",
    "|--|--|--|--|\n",
    "| 10,5,0.1 | 0.9200 | 0.2329 | 8.0s |\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Params Value | RMSE Value | R^2 |Time |\n",
    "|--|--|--|--|\n",
    "| 15,10,0.1 | 0.9114 | 0.2472 | 23.0s |\n",
    "\n",
    "</td>\n",
    "<td >\n",
    "\n",
    "| Params Value | RMSE Value | R^2 |Time |\n",
    "|--|--|--|--|\n",
    "| 15,10,0.15 | **0.9007** | **0.2647** | 26.5s |\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "\n",
    "| Params Value | RMSE Value | R^2 |Time |\n",
    "|--|--|--|--|\n",
    "| 15,10,0.16 | 0.9011 | 0.2641 | 22.5s |\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr> </table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: And? What's next?\n",
    "\n",
    "Several attempts were made to improve on the latent factors with baselines for `user_rating_mean - global_mean` and `item_rating_mean - global_mean` and even temporal adjustments but each time the evaluations performed worse. This is also due to the sparsity of the matrix not giving an accurate representation of a user's or movie's mean. Below is some code we used for these experiments. \n",
    "\n",
    "\n",
    "```\n",
    "global_mean = train_data.groupBy().mean(\"rating\").collect()[0][0]\n",
    "user_mean = train_data.groupBy(\"userId\").mean(\"rating\").withColumnRenamed(\"avg(rating)\", \"user_mean\")\n",
    "movie_mean = train_data.groupBy(\"movieId\").mean(\"rating\").withColumnRenamed(\"avg(rating)\", \"movie_mean\")\n",
    "...\n",
    "predictions = predictions.withColumn('prediction', col('prediction')+ 0.1*(col('user_mean')- global_mean)+ 0.1*(col('movie_mean')- global_mean))\n",
    "```\n",
    "\n",
    "### Recap of Collaboration\n",
    "\n",
    "When it comes to performance the latent factor model required much less computing because of dimension reduction. Although it performed worse with regards to the metrics for our 10K dataset it is expected that with a less sparse and large data set this method would prove to be the winner. In a dataset where the user has more ratings and a less sparse dataset the latent factor would be able to take advantage of the users preferences rather than simply relying on the item-item similarity. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
