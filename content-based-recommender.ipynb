{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, from_json, col, explode, collect_list,concat_ws,lit\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|    id|               title|      original_title|              genres|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|100010|      Flight Command|      Flight Command|           Drama,War|\n",
      "| 10004|         Desperation|         Desperation|Drama,Fantasy,Hor...|\n",
      "|100042|  Dumb and Dumber To|  Dumb and Dumber To|              Comedy|\n",
      "| 10005|Behind Enemy Line...|Behind Enemy Line...|Action,Adventure,...|\n",
      "|100063|            Blackout|            Blackout|     Action,Thriller|\n",
      "| 10013|Peggy Sue Got Mar...|Peggy Sue Got Mar...|Comedy,Drama,Fant...|\n",
      "| 10014|A Nightmare on El...|A Nightmare on El...|              Horror|\n",
      "| 10015|    Heartbreak Ridge|    Heartbreak Ridge|Action,Comedy,Dra...|\n",
      "| 10016|      Ghosts of Mars|      Ghosts of Mars|Action,Horror,Sci...|\n",
      "|100167|         No Way Home|         No Way Home|               Drama|\n",
      "|100196|           Julian Po|           Julian Po|Comedy,Drama,Romance|\n",
      "|100215|         Another Way|      Egymásra nézve|       Drama,History|\n",
      "|100224|How Much Wood Wou...|How Much Wood Wou...|         Documentary|\n",
      "| 10023|             Dragnet|             Dragnet| Action,Comedy,Crime|\n",
      "| 10024|  My Sister's Keeper|  My Sister's Keeper|               Drama|\n",
      "| 10025|        Just My Luck|        Just My Luck|Comedy,Drama,Fami...|\n",
      "|100274|     Comforting Skin|     Comforting Skin|Thriller,Drama,Fa...|\n",
      "|100287|    My Avatar and Me|   Min Avatar og mig|Documentary,Scien...|\n",
      "| 10029|     Very Bad Things|     Very Bad Things|Comedy,Crime,Thri...|\n",
      "|100292|Ain't in It for M...|Ain't in It for M...|         Documentary|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "file = spark.read.csv(os.path.join(\"data/movies_metadata.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "# Select columns we are interested in\n",
    "movies_df = file.select(\"id\", \"title\", \"genres\",\"original_title\").distinct()\n",
    "genres_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert the \"genres\" column to an array of structs\n",
    "movies_df = movies_df.withColumn(\"genres\", from_json(col(\"genres\"), ArrayType(genres_schema)))\n",
    "\n",
    "movies_df = movies_df.select(\"id\",\"original_title\", \"title\", explode(col(\"genres\")).alias(\"genre\")) \\\n",
    "               .select(\"id\",\"original_title\", \"title\", col(\"genre.name\").alias(\"genre_name\")) \\\n",
    "               .dropna()\n",
    "\n",
    "# Group the data by id and title, and collect the genre names into a list\n",
    "movies_df = movies_df.groupBy(\"id\", \"title\",\"original_title\").agg(collect_list(\"genre_name\").alias(\"genres\"))\n",
    "\n",
    "# Combine the genre names into one string\n",
    "movies_df = movies_df.withColumn(\"genres\", concat_ws(\",\", \"genres\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Recommender System (Content-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------------------+-------------------------------------------------------------------------+-------+------------------+--------------------+-------------------+--------------------+-------+-------+-------+-----------+-------+-----+--------+-------------------+-------------------+---+--------------------+--------------------+-------+-----+------------------+------------------+\n",
      "|id    |original_title                                |genres                                                                   |Mystery|Comedy            |Action              |Adventure          |Science Fiction     |Western|Fantasy|Romance|Documentary|Foreign|Music|TV Movie|Animation          |Drama              |War|Horror              |Thriller            |History|Crime|Family            |sum               |\n",
      "+------+----------------------------------------------+-------------------------------------------------------------------------+-------+------------------+--------------------+-------------------+--------------------+-------+-------+-------+-----------+-------+-----+--------+-------------------+-------------------+---+--------------------+--------------------+-------+-----+------------------+------------------+\n",
      "|11052 |Yu-Gi-Oh! The Movie                           |Adventure,Fantasy,Animation,Action,Comedy,Thriller,Science Fiction,Family|0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.028169014084507043|0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.028169014084507043|0.0    |0.0  |0.2676056338028169|0.9014084507042254|\n",
      "|15213 |Everyone's Hero                               |Action,Adventure,Animation,Comedy,Drama,Family                           |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.0                 |0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.04225352112676056|0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8873239436619719|\n",
      "|34003 |Turtles Forever                               |Science Fiction,Adventure,Animation,Action,Family,Comedy                 |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.028169014084507043|0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8732394366197184|\n",
      "|12589 |Jimmy Neutron: Boy Genius                     |Action,Adventure,Animation,Comedy,Family,Fantasy,Science Fiction         |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.028169014084507043|0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8732394366197184|\n",
      "|37776 |Dead Fury                                     |Action,Adventure,Animation,Comedy,Family,Horror                          |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.0                 |0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.028169014084507043|0.0                 |0.0    |0.0  |0.2676056338028169|0.8732394366197183|\n",
      "|16866 |Planet 51                                     |Science Fiction,Animation,Family,Comedy,Adventure                        |0.0    |0.1267605633802817|0.0                 |0.14084507042253522|0.028169014084507043|0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8450704225352113|\n",
      "|140300|Kung Fu Panda 3                               |Action,Adventure,Animation,Comedy,Family                                 |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.0                 |0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8450704225352113|\n",
      "|15511 |VeggieTales: The Pirates Who Don't Do Anything|Adventure,Animation,Comedy,Science Fiction,Family                        |0.0    |0.1267605633802817|0.0                 |0.14084507042253522|0.028169014084507043|0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8450704225352113|\n",
      "|17711 |The Adventures of Rocky & Bullwinkle          |Action,Adventure,Animation,Comedy,Family                                 |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.0                 |0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8450704225352113|\n",
      "|324852|Despicable Me 3                               |Action,Animation,Adventure,Family,Comedy                                 |0.0    |0.1267605633802817|0.028169014084507043|0.14084507042253522|0.0                 |0.0    |0.0    |0.0    |0.0        |0.0    |0.0  |0.0     |0.28169014084507044|0.0                |0.0|0.0                 |0.0                 |0.0    |0.0  |0.2676056338028169|0.8450704225352113|\n",
      "+------+----------------------------------------------+-------------------------------------------------------------------------+-------+------------------+--------------------+-------------------+--------------------+-------+-------+-------+-----------+-------+-----+--------+-------------------+-------------------+---+--------------------+--------------------+-------+-----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_weight_matrix(movies_df, moviesInput, inputRatings):\n",
    "\n",
    "    # Format df so that each column is a genre\n",
    "    genres = movies_df.select(\"genres\").rdd.flatMap(lambda x: x[0].split(',')).distinct().collect()\n",
    "\n",
    "    for genre in genres:\n",
    "        movies_df = movies_df.withColumn(genre, col(\"genres\").contains(genre).cast(\"int\"))\n",
    "\n",
    "    \n",
    "    for i,movie in enumerate(moviesInput):\n",
    "        rating = inputRatings[i]\n",
    "        movie_input_df = movies_df.filter(col('title') == movie)\n",
    "        for genre in genres:\n",
    "            movie_input_df = movie_input_df.withColumn(genre, col(genre) * rating)\n",
    "        movies_df = movies_df.filter(col('title') != movie).union(movie_input_df)\n",
    "    \n",
    "    user_input_movies_df = movies_df.filter(col('title').isin(moviesInput))\n",
    "\n",
    "    # Dataframe with the sum of each column (HERE WE SHOULD ONLY ADD USER INPUT MOVIES AND NORMALIZE THE USER INPUT MOVIES)\n",
    "    genre_sum_df = user_input_movies_df.select([_sum(genre).alias(genre) for genre in genres])\n",
    "    row_values = genre_sum_df.first()\n",
    "\n",
    "    # Sum of total\n",
    "    result = 0\n",
    "    for column_name in genre_sum_df.columns:\n",
    "        value = row_values[column_name]\n",
    "        result += value\n",
    "\n",
    "    # Normalize each genres\n",
    "    genre_sum_df_normalized = genre_sum_df.select(*[(col(genre) / result).alias(genre) for genre in genre_sum_df.columns])\n",
    "\n",
    "    # Create a new dataframe that multiplies each genre value with the corresponding normalized value\n",
    "    multiplied_df = movies_df\n",
    "    for genre in genres:\n",
    "        normalized_genre = genre_sum_df_normalized.select(genre).first()[0]\n",
    "        multiplied_df = multiplied_df.withColumn(genre, col(genre) * normalized_genre)\n",
    "    \n",
    "    # Exclude the input movies from the recommendations AND keep ids in clust\n",
    "    multiplied_df = multiplied_df.filter(~col('title').isin(moviesInput))\n",
    "\n",
    "    # Sum values of a row and store it in a new column called sum then show top 10\n",
    "    final_weighted_matrix = multiplied_df.withColumn('sum', sum(multiplied_df[col] for col in genres))\n",
    "    final_weighted_matrix = final_weighted_matrix.orderBy(\"sum\", ascending=False).limit(10).drop(col(\"title\")).show(truncate=False)\n",
    "\n",
    "\n",
    "# Input movies\n",
    "moviesInput = [\"Brother Bear\", \"Toy Story\", \"The Dark Knight\", \"The Fly\"]\n",
    "\n",
    "# Ratings for the input movies\n",
    "ratings = [10, 9, 1, 1]\n",
    "\n",
    "# Call the recommend_movies function\n",
    "recommended_movies = recommend_movies_weight_matrix(movies_df, moviesInput, ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Train and fit to kmeans model (can change k and seed later)\n",
    "    # kmeans = KMeans(k=20)\n",
    "    # model = kmeans.fit(movies_df.select(\"features\"))\n",
    "    \n",
    "    # # Create a dataframe with the input movies and their ratings\n",
    "    # input_df = spark.createDataFrame(zip(moviesInput, ratings), schema=[\"title\", \"rating\"])\n",
    "\n",
    "    # # Join the input movies with the movies dataframe to get their features\n",
    "    # input_features_df = input_df.join(movies_df, on=\"title\", how=\"inner\").select(\"id\", \"features\", \"rating\")\n",
    "    # print(\"input features df\")\n",
    "    # input_features_df.show()\n",
    "\n",
    "    # print(\"ids of inputs\")\n",
    "\n",
    "    # inputIds = []\n",
    "    # for row in input_features_df.select(\"id\").collect():\n",
    "    #     inputIds.append(row[\"id\"])\n",
    "    # print(inputIds)\n",
    "\n",
    "    # # Make predictions for the input movies using the kmeans model\n",
    "    # predictions_df = model.transform(input_features_df).drop(\"features\")\n",
    "    # print(\"predictions df\")\n",
    "    # predictions_df.show()\n",
    "\n",
    "    # # Get the cluster label for the input movies\n",
    "    # cluster_label = predictions_df.select(\"prediction\").distinct().collect()[0][\"prediction\"]\n",
    "    # print(\"cluster label\")\n",
    "    # print(cluster_label)\n",
    "\n",
    "    # # Get the ids of the movies in the same cluster as the input movies\n",
    "    # cluster_movies_df = model.transform(movies_df).filter(col(\"prediction\") == cluster_label)\n",
    "    # cluster_movies_ids = cluster_movies_df.select(\"id\").rdd.flatMap(lambda x: x).collect()\n",
    "    # print(\"cluster movies id\")\n",
    "    # print(cluster_movies_ids)\n",
    "\n",
    "    # # Exclude the input movies from the recommendations AND keep ids in clust\n",
    "    # recommendations_df = movies_df.filter(col('id').isin(cluster_movies_ids))\n",
    "    # recommendations_df = recommendations_df.filter(~col('id').isin(inputIds))\n",
    "\n",
    "    # print(\"recommendations df (Exclude the input movies from the recommendations AND keep ids in clust)\")\n",
    "    # recommendations_df.show(truncate=False)\n",
    "\n",
    "    # #----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # # Join with the predictions dataframe to get the rating of the recommended movies\n",
    "    # # PROBLEM HERE\n",
    "    # recommendations_df = recommendations_df.join(predictions_df, on=\"id\", how=\"inner\").select(\"title\", \"genres\", \"prediction\", \"rating\")\n",
    "    # print(\"recommendations df (Join with the predictions dataframe to get the rating of the recommended movies)\")\n",
    "    # recommendations_df.show(truncate=False)\n",
    "\n",
    "    # # Sort the recommended movies by their rating and select the top 10\n",
    "    # top_recommendations = recommendations_df.sort(col(\"rating\").desc()).limit(10)\n",
    "\n",
    "    # print(\"top recommendations df\")\n",
    "    # top_recommendations.show(truncate=False)\n",
    "\n",
    "    # return top_recommendations.select(\"title\", \"genres\").rdd.map(lambda x: (x[0], x[1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
