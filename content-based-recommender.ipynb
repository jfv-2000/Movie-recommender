{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Content-Based Recommendations Engine</h1>\n",
    "\n",
    "In this section, we set up the foundation for our content-based movie recommender using weighted matrix and kmeans clustering to evaluate the accuracy of the predicted movies. Our system takes in a list of movies and their respective ratings and then recommends movies that are similar in genres to the liked movies. . The higher the ratings of the movies, the more impact their genres will have on the recommended movies. \n",
    "\n",
    "<h2>Method used</h2>\n",
    "\n",
    "Many methods can be used to build a content-based recommender system. Usually, content-based recommender suggests movies of similar style to the inputted movies. What makes our recommender special is that it allows the user to input their ratings along with their movies, allowing for more flexibility and customization. For example, when using Netflix, their recommender has no way of recommending movies as they have no knowledge of the watch history of the specific user. In our case, the user can enter movies with their specific ratings, and their recommended movies will be specific to the genres and adjusted depending on the ratings. \n",
    "\n",
    "In order for the ratings to have an impact on the recommendation system, we decided to use a weighted matrix due. By using a weighted matrix, we can multiply the ratings of the users by the genres related to the inputted movies, allowing the matrix to represent a specific taste of the user. The total scores of each genres for each movies can then be summed together, and the highest score represents the best recommendations. By doing so, genres of high rated movies will have more impact than other less significant genres, allowing the ratings to impact the recommendations in a significant manner. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4>Step 1: Importing the necessary libraries</h4>\n",
    "\n",
    "Python version 3.10 is used to run the notebook.\n",
    "\n",
    "pip install fo pyspark and matplotlib is required for this to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, from_json, col, explode, collect_list,concat_ws\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 2: Spark Configuration/Setup</h4>\n",
    "\n",
    "We will be using Spark to build our recommender system. Spark is a distributed computing framework that allows us to run our code on a cluster of machines. It's a great tool to use when we want to scale our code to a large dataset. We will be using the pyspark library to run our code on a local machine. We will be using the pyspark.sql library to create our dataframes, and the pyspark.ml library to build our recommender system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Movie Recommender\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 3: Data Preparation/Loading</h4>\n",
    "\n",
    "For our content-based recommender, we will be using `movies_metadata.csv` which contains movies and their features. In this section, we are preparing the data by selecting the columns that we are interested in (id,title, genres, original_title). Furthermore, we are eliminating rows which have missing values since we will not be able to make constructive comparison. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|    id|               title|      original_title|              genres|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|100010|      Flight Command|      Flight Command|           Drama,War|\n",
      "| 10004|         Desperation|         Desperation|Drama,Fantasy,Hor...|\n",
      "|100042|  Dumb and Dumber To|  Dumb and Dumber To|              Comedy|\n",
      "| 10005|Behind Enemy Line...|Behind Enemy Line...|Action,Adventure,...|\n",
      "|100063|            Blackout|            Blackout|     Action,Thriller|\n",
      "| 10013|Peggy Sue Got Mar...|Peggy Sue Got Mar...|Comedy,Drama,Fant...|\n",
      "| 10014|A Nightmare on El...|A Nightmare on El...|              Horror|\n",
      "| 10015|    Heartbreak Ridge|    Heartbreak Ridge|Action,Comedy,Dra...|\n",
      "| 10016|      Ghosts of Mars|      Ghosts of Mars|Action,Horror,Sci...|\n",
      "|100167|         No Way Home|         No Way Home|               Drama|\n",
      "|100196|           Julian Po|           Julian Po|Comedy,Drama,Romance|\n",
      "|100215|         Another Way|      Egymásra nézve|       Drama,History|\n",
      "|100224|How Much Wood Wou...|How Much Wood Wou...|         Documentary|\n",
      "| 10023|             Dragnet|             Dragnet| Action,Comedy,Crime|\n",
      "| 10024|  My Sister's Keeper|  My Sister's Keeper|               Drama|\n",
      "| 10025|        Just My Luck|        Just My Luck|Comedy,Drama,Fami...|\n",
      "|100274|     Comforting Skin|     Comforting Skin|Thriller,Drama,Fa...|\n",
      "|100287|    My Avatar and Me|   Min Avatar og mig|Documentary,Scien...|\n",
      "| 10029|     Very Bad Things|     Very Bad Things|Comedy,Crime,Thri...|\n",
      "|100292|Ain't in It for M...|Ain't in It for M...|         Documentary|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = init_spark()\n",
    "file = spark.read.csv(os.path.join(\"data/movies_metadata.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "# Select columns we are interested in\n",
    "movies_df = file.select(\"id\", \"title\", \"genres\",\"original_title\").distinct()\n",
    "genres_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert the \"genres\" column to an array of structs\n",
    "movies_df = movies_df.withColumn(\"genres\", from_json(col(\"genres\"), ArrayType(genres_schema)))\n",
    "\n",
    "movies_df = movies_df.select(\"id\",\"original_title\", \"title\", explode(col(\"genres\")).alias(\"genre\")) \\\n",
    "               .select(\"id\",\"original_title\", \"title\", col(\"genre.name\").alias(\"genre_name\")) \\\n",
    "               .dropna()\n",
    "\n",
    "# Group the data by id and title, and collect the genre names into a list\n",
    "movies_df = movies_df.groupBy(\"id\", \"title\",\"original_title\").agg(collect_list(\"genre_name\").alias(\"genres\"))\n",
    "\n",
    "# Combine the genre names into one string\n",
    "movies_df = movies_df.withColumn(\"genres\", concat_ws(\",\", \"genres\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 4: Data Modeling</h4>\n",
    "\n",
    "For our data modeling, we are using movies weight matrix to find similar movies to recommend. The method takes in a dataframe movies which represents the dataset, a list of movies taken from the user, a list of ratings taken from the user, and the number of recommendation the user would like. The input movie list and rating list corresponds to the rating for each movie the user has listed. For instance, suppose moviesInput = [movie1, movie2, movie3] and inputRatings = [1,8,9], then the user rates movie1 a rating of 1, movie2 a rating of 8, and movie3 a rating of 9. This means that the user likes movie2 and movie3, and dislikes movie1. \n",
    "\n",
    "From these inputs, we create a matrix using the moviesInput and inputRatings. We can also collect distinct genres that for our movies dataset. Then, we create a matrix using the movie dataset and add columns for distinct genres. For each movie, a value of 1 is assigned to genre columns that the movie has and a value of 0 otherwise. For instance, if movie1 is a Family, Animation, and Comedy movie, a value of 1 will be given under Family, Animation and Comedy columns, and other genres will have a value of 0.  \n",
    "\n",
    "The next step is to multiply these matrices to obtain a matrix that has the weight of the users' ratings. This weighted movie matrix is obtained by multiplying the previous matrices. Then, we normalize each genre to obtain a general factor which represents the user profile. The highest normalized value represents the genre that the user prefers. We also ignore movies from the input list since, the goal of a recommender is to give movie suggestion that are not part of the input. \n",
    "\n",
    "Afterwards, we multiply the user profile matrix with our dataset to obtain a new weighted movies matrix which will be used to find the movies that the user will like. We sum all genre rows into a value and the highest score will be the movie that the recommender recommends to the user. The higher the score, the more likely the user will enjoy the movie since the recommend movies ressembles the liked input movies that the user rated. Finally, we return the number of recommendations the user wanted based on a decreasing order of the sum column. \n",
    "\n",
    "The following are the generalized steps used for our data modeling:\n",
    "1. Create a matrix using input user ratings\n",
    "2. Collect distinct genres \n",
    "3. Create a matrix using movies from the data preparation `movies_df`\n",
    "    - Create a column for each genres\n",
    "    - For each row, we add a value of 1 if the movie is part of the genre otherwise the value is 0\n",
    "4. Multiply input user ratings matrix (step 1) with movies matrix (step 3) and obtain the weighted genre matrix\n",
    "5. Aggregate the weighted genres and normalize them to create a user profile to know which genres the user likes \n",
    "6. Mutiply the normalized user profile with the candidate movies to obtain a weighted movies matrix\n",
    "7. Sum all columns to get a score for each movie\n",
    "8. Recommended movies with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies_weight_matrix(movies_df, moviesInput, inputRatings, numberOfRecommendation):\n",
    "\n",
    "    # Format df so that each column is a genre\n",
    "    genres = movies_df.select(\"genres\").rdd.flatMap(lambda x: x[0].split(',')).distinct().collect()\n",
    "\n",
    "    # Create a PySpark dataframe containing the input titles\n",
    "    original_input_df = movies_df.filter(col(\"title\").isin(moviesInput))\n",
    "\n",
    "    for genre in genres:\n",
    "        movies_df = movies_df.withColumn(genre, col(\"genres\").contains(genre).cast(\"int\"))\n",
    "        original_input_df = original_input_df.withColumn(genre, col(\"genres\").contains(genre).cast(\"int\"))\n",
    "\n",
    "    # Multiply the inputRatings with movie matrix with each matrix\n",
    "    for i,movie in enumerate(moviesInput):\n",
    "        rating = inputRatings[i]\n",
    "        movie_input_df = movies_df.filter(col('title') == movie)\n",
    "        for genre in genres:\n",
    "            movie_input_df = movie_input_df.withColumn(genre, col(genre) * rating)\n",
    "        movies_df = movies_df.filter(col('title') != movie).union(movie_input_df)\n",
    "    \n",
    "    user_input_movies_with_ratings_df = movies_df.filter(col('title').isin(moviesInput))\n",
    "\n",
    "    # Dataframe with the sum of each column (HERE WE SHOULD ONLY ADD USER INPUT MOVIES AND NORMALIZE THE USER INPUT MOVIES)\n",
    "    genre_sum_df = user_input_movies_with_ratings_df.select([_sum(genre).alias(genre) for genre in genres])\n",
    "    row_values = genre_sum_df.first()\n",
    "\n",
    "    # Sum of total\n",
    "    result = 0\n",
    "    for column_name in genre_sum_df.columns:\n",
    "        value = row_values[column_name]\n",
    "        result += value\n",
    "\n",
    "    # Normalize each genres\n",
    "    genre_sum_df_normalized = genre_sum_df.select(*[(col(genre) / result).alias(genre) for genre in genre_sum_df.columns])\n",
    "\n",
    "    # Create a new dataframe that multiplies each genre value with the corresponding normalized value\n",
    "    multiplied_df = movies_df\n",
    "    input_multiplied_df = original_input_df\n",
    "    for genre in genres:\n",
    "        normalized_genre = genre_sum_df_normalized.select(genre).first()[0]\n",
    "        multiplied_df = multiplied_df.withColumn(genre, col(genre) * normalized_genre)\n",
    "        input_multiplied_df = input_multiplied_df.withColumn(genre, col(genre) * normalized_genre)\n",
    "    \n",
    "    # Exclude the input movies from the recommendations AND keep ids in clust\n",
    "    multiplied_df = multiplied_df.filter(~col('title').isin(moviesInput))\n",
    "    \n",
    "    # Sum values of a row and store it in a new column called sum then show top 10\n",
    "    final_weighted_matrix = multiplied_df.withColumn('sum', sum(multiplied_df[col] for col in genres))\n",
    "    final_weighted_matrix = final_weighted_matrix.orderBy(\"sum\", ascending=False).limit(numberOfRecommendation)\n",
    "    \n",
    "    return final_weighted_matrix\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 5: Data Prediction</h4>\n",
    "\n",
    "For the movie prediction, we get the input movies from the user with each movie ratings and feed them to our method from the last step `recommend_movies_weight_matrix` with the number of recommendation we want. You can change the moviesInput and ratings list for different recommendation but note that movies must be in the database otherwise it cannot be found. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 8) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/homebrew/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m numberOfRecommendation \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Call the recommend_movies function\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m recommended_movies_weight_matrix \u001b[39m=\u001b[39m recommend_movies_weight_matrix(movies_df, moviesInput, ratings, numberOfRecommendation)\n\u001b[1;32m     10\u001b[0m recommended_movies_weight_matrix\u001b[39m.\u001b[39mshow(truncate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mrecommend_movies_weight_matrix\u001b[0;34m(movies_df, moviesInput, inputRatings, numberOfRecommendation)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecommend_movies_weight_matrix\u001b[39m(movies_df, moviesInput, inputRatings, numberOfRecommendation):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[39m# Format df so that each column is a genre\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     genres \u001b[39m=\u001b[39m movies_df\u001b[39m.\u001b[39;49mselect(\u001b[39m\"\u001b[39;49m\u001b[39mgenres\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mrdd\u001b[39m.\u001b[39mflatMap(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mdistinct()\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Create a PySpark dataframe containing the input titles\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     original_input_df \u001b[39m=\u001b[39m movies_df\u001b[39m.\u001b[39mfilter(col(\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39misin(moviesInput))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/dataframe.py:175\u001b[0m, in \u001b[0;36mDataFrame.rdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the content as an :class:`pyspark.RDD` of :class:`Row`.\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_rdd \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     jrdd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mjavaToPython()\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_rdd \u001b[39m=\u001b[39m RDD(\n\u001b[1;32m    177\u001b[0m         jrdd, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession\u001b[39m.\u001b[39m_sc, BatchedSerializer(CPickleSerializer())\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_rdd\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 3) / 3]\r"
     ]
    }
   ],
   "source": [
    "# Input movies and Ratings for the input movies\n",
    "moviesInput=[\"Popular Music\",\"The Terminal\",\"Donnie Darko\",\"Blood Diamond\",\"Three-Step Dance\"]\n",
    "ratings=[1, 10, 3, 10, 3]\n",
    "# moviesInput = [\"Brother Bear\", \"Toy Story\", \"The Dark Knight\",\"Heat\"]\n",
    "# ratings = [10, 9, 1, 2 ]\n",
    "numberOfRecommendation = 100\n",
    "\n",
    "# Call the recommend_movies function\n",
    "recommended_movies_weight_matrix = recommend_movies_weight_matrix(movies_df, moviesInput, ratings, numberOfRecommendation)\n",
    "recommended_movies_weight_matrix.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 6: Model Evaluation</h4>\n",
    "\n",
    "A method for validating our results was very challenging to think of, as unsupervised recommenders do not have many options in terms of metrics. The method used to validate our recommendations is to build a k-means clustering model which recommends movies of the same cluster. We then put the recommended movies from our results into the model, and see if the movies input is found in the same cluster. If the recommended movies and the inputted movies are of the same cluster, it proves that they are similar and that it is a good recommendation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jefan\\Documents\\Movie-recommender\\content-based-recommender.ipynb Cell 13\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m liked_moviesInput\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mThe Terminal\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mBlood Diamond\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Call the recommend_movies function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m recommended_movies \u001b[39m=\u001b[39m recommend_movies_kmeans(movies_df, liked_moviesInput, recommended_movies_weight_matrix, numberOfRecommendation)\n",
      "\u001b[1;32mc:\\Users\\jefan\\Documents\\Movie-recommender\\content-based-recommender.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m genre \u001b[39min\u001b[39;00m genres:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         movie_input_df \u001b[39m=\u001b[39m movie_input_df\u001b[39m.\u001b[39mwithColumn(genre, col(genre))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     movies_df \u001b[39m=\u001b[39m movies_df\u001b[39m.\u001b[39;49mfilter(col(\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m!=\u001b[39;49m movie)\u001b[39m.\u001b[39;49munion(liked_moviesInput)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Create feature vector\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefan/Documents/Movie-recommender/content-based-recommender.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m assembler \u001b[39m=\u001b[39m VectorAssembler(inputCols\u001b[39m=\u001b[39mgenres, outputCol\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:2257\u001b[0m, in \u001b[0;36mDataFrame.union\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   2247\u001b[0m \u001b[39m@since\u001b[39m(\u001b[39m2.0\u001b[39m)\n\u001b[0;32m   2248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munion\u001b[39m(\u001b[39mself\u001b[39m, other: \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   2249\u001b[0m     \u001b[39m\"\"\"Return a new :class:`DataFrame` containing union of rows in this and another\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m \u001b[39m    :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   2251\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2255\u001b[0m \u001b[39m    Also as standard in SQL, this function resolves columns by position (not by name).\u001b[39;00m\n\u001b[0;32m   2256\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2257\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39munion(other\u001b[39m.\u001b[39;49m_jdf), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "def recommend_movies_kmeans(movies_df, liked_moviesInput, recommended_movies_weight_matrix, numberOfRecommendation):\n",
    "    # Assume that the movies input are only movies that are liked by the users\n",
    "    # Train kmean model\n",
    "    # Get predictions of cluster number of movies input\n",
    "    # Filter to search for recommended movies\n",
    "    # Show filter\n",
    "\n",
    "    # Format df so that each column is a genre\n",
    "    genres = movies_df.select(\"genres\").rdd.flatMap(lambda x: x[0].split(',')).distinct().collect()\n",
    "    for genre in genres:\n",
    "        movies_df = movies_df.withColumn(genre, col(\"genres\").contains(genre).cast(\"int\"))\n",
    "    for movie in liked_moviesInput:\n",
    "        movie_input_df = movies_df.filter(col('title') == movie)\n",
    "        for genre in genres:\n",
    "            movie_input_df = movie_input_df.withColumn(genre, col(genre))\n",
    "        movies_df = movies_df.filter(col('title') != movie).union(movie_input_df)\n",
    "\n",
    "    # Create feature vector\n",
    "    assembler = VectorAssembler(inputCols=genres, outputCol=\"features\")\n",
    "\n",
    "    movies_df = assembler.transform(movies_df)\n",
    "\n",
    "    # Format input movies as df\n",
    "    user_input_movies_df = movies_df.filter(col('title').isin(liked_moviesInput))\n",
    "\n",
    "    # Cluster movies using KMeans\n",
    "    kmeans = KMeans(k=10)\n",
    "    model = kmeans.fit(movies_df.select(\"features\"))\n",
    "\n",
    "    # Get cluster labels for all movies\n",
    "    clustered = model.transform(movies_df)\n",
    "\n",
    "    # Get cluster labels for user input movies\n",
    "    user_clustered = model.transform(user_input_movies_df).withColumnRenamed(\"title\", \"user_title\")\n",
    "    user_predictions = user_clustered.select('prediction').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    # Get recommended movies from same clusters as user input movies\n",
    "    cluster_movies_df = clustered.filter(col('prediction').isin(user_predictions)).filter(~col('title').isin(liked_moviesInput))\n",
    "\n",
    "    # Get the cluster number for the recommended_movies from weight matrix \n",
    "    list_of_recommended_movies = recommended_movies_weight_matrix.select('id').rdd.flatMap(lambda x: x).collect()\n",
    "    recommended_movies_df = cluster_movies_df.filter(col('id').isin(list_of_recommended_movies))\n",
    "    # recommended_movies_df.show(truncate=False)\n",
    " \n",
    "    print(\"Performance metric (accuracy): \" + str(recommended_movies_df.count() / numberOfRecommendation))\n",
    "    return recommended_movies_df.count() / numberOfRecommendation\n",
    "   \n",
    "\n",
    "# Input movies\n",
    "liked_moviesInput=[\"The Terminal\",\"Blood Diamond\"]\n",
    "\n",
    "# Call the recommend_movies function\n",
    "recommended_movies = recommend_movies_kmeans(movies_df, liked_moviesInput, recommended_movies_weight_matrix, numberOfRecommendation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Step 7: Model Performance</h4>\n",
    "\n",
    "For our model performance, we evaluate the accuracy of the recommended movies for different number of recommendations. We use `recommend_movies_kmeans` with different number of recommendations to get the accuracy and plot it. Looking at the plot generated from the code below, we can observe that the more movies we want recommended, the less accurate the movies are. This can be explained by the sparsity of our data and that we are running out of movies that ressembles the input list. Therefore, the algorithm suggests movies that the user may like but eventually, at a certain point, there is a limited number of movies that are similar to each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nb_recommendation = []\n",
    "y_accuracy = []\n",
    "\n",
    "for i in range(50,601,50):\n",
    "    recommended_movies_weight_matrix = recommend_movies_weight_matrix(movies_df, moviesInput, ratings, i)\n",
    "    temp_accuracy = recommend_movies_kmeans(movies_df, liked_moviesInput, recommended_movies_weight_matrix, i)\n",
    "    x_nb_recommendation.append(i)\n",
    "    y_accuracy.append(temp_accuracy)\n",
    "\n",
    "y_accuracy = [round(num, 5) for num in y_accuracy]  \n",
    "\n",
    "print(x_nb_recommendation)\n",
    "print(y_accuracy)\n",
    "\n",
    "plt.plot(x_nb_recommendation, y_accuracy, 'ro')\n",
    "plt.xlabel('x - number of recommendation')\n",
    "plt.ylabel('y - accuracy')\n",
    "plt.title(\"Accuracy of Content-Based Recommendation System for different number of recommendation\")\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Recap of Content-Based recommender system</h4>\n",
    "\n",
    "The content-based recommender system is a recommendation system that suggests items based on the similarity of the item's features to the user's preferences. In our case, we made our recommender in a way so that it would be able to include the user's ratings over the movies which are inputted into the system, allowing for more flexibility and customization over their recommendations. Our recommender system then recommends movies based on genres similarity, and puts more emphasis over those with a higher rating based on the input of the users.\n",
    "\n",
    "A downside of our recommender system is that it is limited to recommending items that are similar to the inputted movies, and may not be able to recommend items which does not have the same genre scope. An alternative to that would be collaborative, where we match user's preference to other similar types of user ratings. Furthermore, since our database of movie is sparse, some movies have a large number of genre attached to it while others only have one genre. Due to the fact that we use a weighted matrix, this can greatly affect the accuracy of our recommender system since movies with multiple genres have more chance to be recommended, as the total sum is impacted by their multiple genres. A minor solution can be to give a very high rating to movies which are liked, as it would impact their sum in a way which makes the multiple genres less significant, or to put movies which are very disliked a rating of 0, which will nullify the impact of their multiple ratings as they will have a value of 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
