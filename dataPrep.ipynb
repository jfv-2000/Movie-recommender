{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, from_json, col, explode, collect_list,concat_ws,lit\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "movies_df = spark.read.csv(os.path.join(\"data/movies_metadata.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "# Select columns we are interested in\n",
    "movies_df = movies_df.select(\"id\", \"title\", \"genres\").distinct()\n",
    "genres_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert the \"genres\" column to an array of structs\n",
    "movies_df = movies_df.withColumn(\"genres\", from_json(col(\"genres\"), ArrayType(genres_schema)))\n",
    "\n",
    "movies_df = movies_df.select(\"id\", \"title\", explode(col(\"genres\")).alias(\"genre\")) \\\n",
    "               .select(\"id\", \"title\", col(\"genre.name\").alias(\"genre_name\")) \\\n",
    "               .dropna()\n",
    "\n",
    "# Group the data by id and title, and collect the genre names into a list\n",
    "movies_df = movies_df.groupBy(\"id\", \"title\").agg(collect_list(\"genre_name\").alias(\"genres\"))\n",
    "\n",
    "# Combine the genre names into one string\n",
    "movies_df = movies_df.withColumn(\"genres\", concat_ws(\",\", \"genres\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies_weight_matrix(movies_df, moviesInput, inputRatings):\n",
    "\n",
    "    # Format df so that each column is a genre\n",
    "    genres = movies_df.select(\"genres\").rdd.flatMap(lambda x: x[0].split(',')).distinct().collect()\n",
    "\n",
    "    for genre in genres:\n",
    "        movies_df = movies_df.withColumn(genre, col(\"genres\").contains(genre).cast(\"int\"))\n",
    "\n",
    "    for i,movie in enumerate(moviesInput):\n",
    "        rating = inputRatings[i]\n",
    "        movie_input_df = movies_df.filter(col('title') == movie)\n",
    "        for genre in genres:\n",
    "            movie_input_df = movie_input_df.withColumn(genre, col(genre) * rating)\n",
    "        movies_df = movies_df.filter(col('title') != movie).union(movie_input_df)\n",
    "    \n",
    "    user_input_movies_df = movies_df.filter(col('title').isin(moviesInput))\n",
    "\n",
    "    # Dataframe with the sum of each column (HERE WE SHOULD ONLY ADD USER INPUT MOVIES AND NORMALIZE THE USER INPUT MOVIES)\n",
    "    genre_sum_df = user_input_movies_df.select([_sum(genre).alias(genre) for genre in genres])\n",
    "    row_values = genre_sum_df.first()\n",
    "\n",
    "    # Sum of total\n",
    "    result = 0\n",
    "    for column_name in genre_sum_df.columns:\n",
    "        value = row_values[column_name]\n",
    "        result += value\n",
    "\n",
    "    # Normalize each genres\n",
    "    genre_sum_df_normalized = genre_sum_df.select(*[(col(genre) / result).alias(genre) for genre in genre_sum_df.columns])\n",
    "\n",
    "    # Create a new dataframe that multiplies each genre value with the corresponding normalized value\n",
    "    multiplied_df = movies_df\n",
    "    for genre in genres:\n",
    "        normalized_genre = genre_sum_df_normalized.select(genre).first()[0]\n",
    "        multiplied_df = multiplied_df.withColumn(genre, col(genre) * normalized_genre)\n",
    "    \n",
    "    # Exclude the input movies from the recommendations AND keep ids in clust\n",
    "    multiplied_df = multiplied_df.filter(~col('title').isin(moviesInput))\n",
    "\n",
    "    # Sum values of a row and store it in a new column called sum then show top 10\n",
    "    final_weighted_matrix = multiplied_df.withColumn('sum', sum(multiplied_df[col] for col in genres))\n",
    "    final_weighted_matrix = final_weighted_matrix.orderBy(\"sum\", ascending=False).limit(10).show(truncate=False)\n",
    "\n",
    "\n",
    "# Input movies\n",
    "moviesInput = [\"Brother Bear\", \"Toy Story\", \"The Dark Knight\", \"The Fly\"]\n",
    "\n",
    "# Ratings for the input movies\n",
    "ratings = [10, 9, 0, 1]\n",
    "\n",
    "# Call the recommend_movies function\n",
    "recommended_movies = recommend_movies_weight_matrix(movies_df, moviesInput, ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Train and fit to kmeans model (can change k and seed later)\n",
    "    # kmeans = KMeans(k=20)\n",
    "    # model = kmeans.fit(movies_df.select(\"features\"))\n",
    "    \n",
    "    # # Create a dataframe with the input movies and their ratings\n",
    "    # input_df = spark.createDataFrame(zip(moviesInput, ratings), schema=[\"title\", \"rating\"])\n",
    "\n",
    "    # # Join the input movies with the movies dataframe to get their features\n",
    "    # input_features_df = input_df.join(movies_df, on=\"title\", how=\"inner\").select(\"id\", \"features\", \"rating\")\n",
    "    # print(\"input features df\")\n",
    "    # input_features_df.show()\n",
    "\n",
    "    # print(\"ids of inputs\")\n",
    "\n",
    "    # inputIds = []\n",
    "    # for row in input_features_df.select(\"id\").collect():\n",
    "    #     inputIds.append(row[\"id\"])\n",
    "    # print(inputIds)\n",
    "\n",
    "    # # Make predictions for the input movies using the kmeans model\n",
    "    # predictions_df = model.transform(input_features_df).drop(\"features\")\n",
    "    # print(\"predictions df\")\n",
    "    # predictions_df.show()\n",
    "\n",
    "    # # Get the cluster label for the input movies\n",
    "    # cluster_label = predictions_df.select(\"prediction\").distinct().collect()[0][\"prediction\"]\n",
    "    # print(\"cluster label\")\n",
    "    # print(cluster_label)\n",
    "\n",
    "    # # Get the ids of the movies in the same cluster as the input movies\n",
    "    # cluster_movies_df = model.transform(movies_df).filter(col(\"prediction\") == cluster_label)\n",
    "    # cluster_movies_ids = cluster_movies_df.select(\"id\").rdd.flatMap(lambda x: x).collect()\n",
    "    # print(\"cluster movies id\")\n",
    "    # print(cluster_movies_ids)\n",
    "\n",
    "    # # Exclude the input movies from the recommendations AND keep ids in clust\n",
    "    # recommendations_df = movies_df.filter(col('id').isin(cluster_movies_ids))\n",
    "    # recommendations_df = recommendations_df.filter(~col('id').isin(inputIds))\n",
    "\n",
    "    # print(\"recommendations df (Exclude the input movies from the recommendations AND keep ids in clust)\")\n",
    "    # recommendations_df.show(truncate=False)\n",
    "\n",
    "    # #----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # # Join with the predictions dataframe to get the rating of the recommended movies\n",
    "    # # PROBLEM HERE\n",
    "    # recommendations_df = recommendations_df.join(predictions_df, on=\"id\", how=\"inner\").select(\"title\", \"genres\", \"prediction\", \"rating\")\n",
    "    # print(\"recommendations df (Join with the predictions dataframe to get the rating of the recommended movies)\")\n",
    "    # recommendations_df.show(truncate=False)\n",
    "\n",
    "    # # Sort the recommended movies by their rating and select the top 10\n",
    "    # top_recommendations = recommendations_df.sort(col(\"rating\").desc()).limit(10)\n",
    "\n",
    "    # print(\"top recommendations df\")\n",
    "    # top_recommendations.show(truncate=False)\n",
    "\n",
    "    # return top_recommendations.select(\"title\", \"genres\").rdd.map(lambda x: (x[0], x[1])).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
